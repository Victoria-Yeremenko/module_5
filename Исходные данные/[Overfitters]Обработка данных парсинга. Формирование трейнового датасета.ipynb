{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование трейнового датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели мы будем использовать данные, которые при помощи парсинга получили самостоятельно с сайта auto.ru, \n",
    "а также датасет, который был собран в рамках соревнования ранее (08.11.2020, далее - \"ноябрьский датасет\") и выложен на Каггл.\n",
    "\n",
    "В данном файле пример обработки собранных данных. Данные, полученные позднее, обрабатывались таким же образом.\n",
    "\n",
    "Свои данные мы приведем к формату ноябрьского датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 550) # больше колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Результаты парсинга всех машин по России от 22.02.21\n",
    "latest_df = pd.read_csv('allCars22.02.2021.csv')\n",
    "\n",
    "# Результаты парсинга машин по Москве и МО от 23.02.21\n",
    "latest_moscow_df = pd.read_csv('all_moscow+200km.csv')\n",
    "\n",
    "# Данные с Каггла - парсинг по Москве и области от 08.11.20\n",
    "eda_df = pd.read_csv('car_price_08_11_2020_final.csv')\n",
    "\n",
    "# Тестовый датасет\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сначала разбираемся с результатами своего парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    \"\"\"Функция первичной очистки данных после парсинга\"\"\"\n",
    "    \n",
    "    data = df.copy()\n",
    "    # Удаляем ненужные колонки\n",
    "    data.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "\n",
    "    # В данные попадают заголовки для csv-таблицы. Удалим их\n",
    "    data = data.loc[data.brand != 'brand']\n",
    "\n",
    "    # Удалим дубли по признаку sell_id\n",
    "    data.drop_duplicates(subset=['sell_id'], keep='last', inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def id_set(df):\n",
    "    \"\"\" Функция возвращает уникальные id объявлений в датасете\"\"\"\n",
    "      \n",
    "    return set(df['sell_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of latest_df: (170306, 35)\n",
      "Size of latest_moscow_df: (50496, 35)\n"
     ]
    }
   ],
   "source": [
    "# Исходные размеры датасетов\n",
    "print(f\"Size of latest_df: {latest_df.shape}\")\n",
    "print(f\"Size of latest_moscow_df: {latest_moscow_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список уникальных id объявлений для проверки совпадений в датасетах\n",
    "latest_id = id_set(latest_df)\n",
    "latest_moscow_id = id_set(latest_moscow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37556"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Количество пересечений. За один день в Москве подали 11,5 тыс объявлений??? Странно...\n",
    "intersect = latest_id & latest_moscow_id\n",
    "len(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of latest_df: (130424, 35)\n"
     ]
    }
   ],
   "source": [
    "# Удалим пересечения с Москвой\n",
    "latest_df = latest_df[latest_df['sell_id'].isin(intersect) == False]\n",
    "print(f\"Size of latest_df: {latest_df.shape}. {len(intersect)} intersections deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем локацию, тк мы собирали данные по всей России (0), а не только по Москве и МО (1)\n",
    "latest_df['moscow'] = 0\n",
    "latest_moscow_df['moscow'] = 1\n",
    "eda_df['moscow'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of parsed_data: (180920, 36)\n"
     ]
    }
   ],
   "source": [
    "# Объединяем данные парсинга\n",
    "parsed_data = pd.concat([latest_df, latest_moscow_df], ignore_index=True)\n",
    "print(f\"Size of parsed_data: {parsed_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of parsed_data: (176684, 35)\n"
     ]
    }
   ],
   "source": [
    "parsed_data = data_cleaning(parsed_data)\n",
    "print(f\"Size of parsed_data: {parsed_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразуем признаки для соответствия ноябрьскому датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словари для преобразования признаков\n",
    "\n",
    "fuel_type_converter = {\n",
    "    'GASOLINE': 'бензин',\n",
    "    'DIESEL': 'дизель',\n",
    "    'HYBRID': 'гибрид',\n",
    "    'ELECTRO': 'электро',\n",
    "    'LPG': 'газ',\n",
    "}\n",
    "\n",
    "color_convertor = {\n",
    "    '040001': 'черный',\n",
    "    'FAFBFB': 'белый',\n",
    "    '0000CC': 'синий',\n",
    "    '97948F': 'серый',\n",
    "    'CACECB': 'серебристый',\n",
    "    '200204': 'коричневый',\n",
    "    'EE1D19': 'красный',\n",
    "    '007F00': 'зелёный',\n",
    "    '22A0F8': 'голубой',\n",
    "    'C49648': 'бежевый.',\n",
    "    'DEA522': 'золотистый',\n",
    "    'FF8649': 'оранжевый',\n",
    "    '660099': 'фиолетовый',\n",
    "    '4A2197': 'пурпурный',\n",
    "    'FFD600': 'жёлтый',\n",
    "    'FFC0CB': 'розовый',    \n",
    "}\n",
    "\n",
    "wheel_convertor = {\n",
    "    'LEFT': 'Левый',\n",
    "    'RIGHT': 'Правый',\n",
    "}\n",
    "\n",
    "transmission_converter = {\n",
    "    'MECHANICAL': 'механическая',\n",
    "    'AUTOMATIC': 'автоматическая',\n",
    "    'ROBOT': 'роботизированная',\n",
    "    'VARIATOR': 'вариаторная'\n",
    "}\n",
    "\n",
    "gear_type_convertor = {\n",
    "    'REAR_DRIVE': 'задний',\n",
    "    'ALL_WHEEL_DRIVE': 'полный',\n",
    "    'FORWARD_CONTROL': 'передний',\n",
    "}\n",
    "\n",
    "pts_convertor = {\n",
    "    'ORIGINAL': 'Оригинал',\n",
    "    'DUPLICATE': 'Дубликат',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of parsed_data: (176677, 35)\n"
     ]
    }
   ],
   "source": [
    "# Несколько строчек съехали. Удалим их\n",
    "colors = list(color_convertor.keys())\n",
    "parsed_data = parsed_data[parsed_data['color_hex'].isin(colors)]\n",
    "print(f\"Size of parsed_data: {parsed_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже та же обработка, которая была сделана для ноябрьского датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_features(df):\n",
    "    \"\"\" Функция преобразования признаков к виду тестового датасета\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    data.fuelType.replace(fuel_type_converter, inplace=True)\n",
    "\n",
    "    # преобразуем значения цветов из hex-формата в строчное название цвета\n",
    "    data['color'] = data.color_hex.apply(lambda x: color_convertor[x])\n",
    "    data.drop(labels='color_hex', axis=1, inplace=True)\n",
    "    \n",
    "    # Преобразуем признак steering_wheel\n",
    "    data['Руль'].replace(wheel_convertor, inplace=True)\n",
    "    \n",
    "    # Преобразуем признак vehicleTransmission\n",
    "    data.vehicleTransmission.replace(transmission_converter, inplace=True)\n",
    "    \n",
    "    # Преобразуем признак gear_type\n",
    "    data['Привод'].replace(gear_type_convertor, inplace=True)\n",
    "    \n",
    "    # Преобразуем признак ПТС\n",
    "    data['ПТС'].replace(pts_convertor, inplace=True)\n",
    "    \n",
    "      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = convert_features(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of parsed_data: (176000, 35)\n"
     ]
    }
   ],
   "source": [
    "# удалим объекты без цены и с пропусками в след. признаках\n",
    "# удаление нужно в т.ч.для того, чтобы перевести данные в int(Nan в int не переводятся)\n",
    "cols_to_dropna = 'bodyType engineDisplacement enginePower fuelType modelDate name numberOfDoors super_gen vehicleConfiguration vehicleTransmission Привод price price_segment'.split(' ')\n",
    "\n",
    "parsed_data = parsed_data.dropna(subset=cols_to_dropna, axis=0)\n",
    "print(f\"Size of parsed_data: {parsed_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object    34\n",
       "int64      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Почти все данные получились типа 'object'. В дальнейшем это надо исправить \n",
    "parsed_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим, какие признаки в ноябрьском датасете числовые\n",
    "int_types = eda_df.dtypes[eda_df.dtypes == 'int64'].index.to_list()\n",
    "float_types = eda_df.dtypes[eda_df.dtypes == 'float64'].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим в соответствие\n",
    "parsed_data[int_types] = parsed_data[int_types].astype('int64')\n",
    "parsed_data[float_types] = parsed_data[float_types].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай сохраняем промежуточный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data, file_name):\n",
    "    data.to_csv(f\"{file_name}.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(parsed_data, 'parsed_data_22_02_2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем датасет с Каггла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of eda_df: (57708, 36)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of eda_df: {eda_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздадим список уникальных id датасетов. На этот раз все id принадлежат типу int, можно сравнивать.\n",
    "# Сравнивать их ранее было бы некорректно.\n",
    "parsed_data_id = id_set(parsed_data)\n",
    "eda_id = id_set(eda_df)\n",
    "test_id = id_set(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of eda_df: (49817, 36). 7891 intersections deleted\n"
     ]
    }
   ],
   "source": [
    "# Проверим пересечения ноябрьского датасета с нашим датасетом и удалим их\n",
    "intersect = parsed_data_id & eda_id\n",
    "eda_df = eda_df[eda_df['sell_id'].isin(intersect) == False]\n",
    "print(f\"Size of eda_df: {eda_df.shape}. {len(intersect)} intersections deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of full_data: (225817, 36)\n"
     ]
    }
   ],
   "source": [
    "# Соединяем в общий датасет\n",
    "full_data = parsed_data.append(eda_df, sort=False).reset_index(drop=True)\n",
    "print(f\"Size of full_data: {full_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225817"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем. Получилось - все sell_id уникальны\n",
    "full_data.sell_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of full_data: (203234, 36). 22583 intersections deleted\n"
     ]
    }
   ],
   "source": [
    "# проверим пересечения объединенного датасета с тестом и удалим их. 22583 пересечения!\n",
    "full_data_id = id_set(full_data)\n",
    "intersect = test_id & full_data_id\n",
    "full_data = full_data[full_data['sell_id'].isin(intersect) == False]\n",
    "print(f\"Size of full_data: {full_data.shape}. {len(intersect)} intersections deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203234"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.sell_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраняем результат. Это и будет наш трейновый датасет.\n",
    "\n",
    "Трейновый датасет не содержит пересечений с тестом. \n",
    "\n",
    "В трейновом датасете есть колонка \"moscow\", которой нет в тестовом датасете (1 - Москва и МО, 2 - вся остальная территория России)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(full_data, 'train_22_02_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
